{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## JSONL データ　保存",
   "id": "761ccb5c9c4b5f37"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T11:17:12.207630Z",
     "start_time": "2024-08-09T11:16:45.784696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# \n",
    "from openai import OpenAI\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "\n",
    "class CreateFineTuningData:\n",
    "    def __init__(self, api_key):\n",
    "        # openai.api_key = api_key\n",
    "        self.data = []\n",
    "\n",
    "    def read_document(self, file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            return file.read()\n",
    "\n",
    "    def split_into_paragraphs(self, content):\n",
    "        paragraphs = content.split('\\n\\n')\n",
    "        return [p.strip() for p in paragraphs if p.strip()]\n",
    "\n",
    "    def generate_question(self, paragraph, title):\n",
    "        client = OpenAI()\n",
    "        prompt=\"The title of this document is: vision. From the attached document, create at least 10 QA data (Q: prompt, A: completion) to fine-tune the chatgpt: here is an example output. {\\\"prompt\\\":\\\"<prompt text>\\\", \\\"completion\\\":\\\"<ideal generated text>\\\"} The content to be described is as follows. 'Overview', 'Quick start', 'Preparation', 'Usage examples', 'How to use', 'Process flow', 'Advanced settings', 'Functional details', 'Limitations', 'FAQs (if any) Use as is.:\\n\\n{paragraph}\"\n",
    "        \n",
    "        max_retries = 3\n",
    "        retry_delay = 5  # 秒単位での待ち時間\n",
    "\n",
    "        for attempt in range(max_retries):\n",
    "            # try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\",\n",
    "                     \"content\": \"You are a professional python developer, a helpful assistant and good at chatgpt APIs.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                ],\n",
    "                max_tokens=50,\n",
    "                n=1,\n",
    "                stop=None,\n",
    "                temperature=0.5\n",
    "            )\n",
    "            # message = completion.choices[0].message.content\n",
    "            return response.choices[0].message.content\n",
    "            # except client.error.Timeout as e:\n",
    "            #     if attempt < max_retries - 1:\n",
    "            #         print(f\"Timeout occurred. Retrying in {retry_delay} seconds...\")\n",
    "            #         time.sleep(retry_delay)\n",
    "            #     else:\n",
    "            #         print(\"Max retries reached. Exiting.\")\n",
    "            #         raise e\n",
    "\n",
    "    def create_fine_tuning_data(self, content, title):\n",
    "        paragraphs = self.split_into_paragraphs(content)\n",
    "        for i, paragraph in enumerate(paragraphs):\n",
    "            if i >= 20:  # 20件のQAペアを作成\n",
    "                break\n",
    "            question = self.generate_question(paragraph, title)\n",
    "            self.data.append({\"prompt\": question, \"completion\": paragraph})\n",
    "\n",
    "    def save_to_jsonl(self, filename):\n",
    "        with open(filename, 'w') as f:\n",
    "            for entry in self.data:\n",
    "                f.write(json.dumps(entry) + \"\\n\")\n",
    "        print(f\"Data saved to {filename}\")\n",
    "\n",
    "def main():\n",
    "    api_key = os.getenv('OPENAI_API_KEY')  # OpenAI APIキーを入力\n",
    "    \n",
    "    file_path = './document/02_vision.txt'  # 読み込むファイルのパス\n",
    "    output_filename = 'fine_tuning_data.jsonl'  # 保存するファイル名\n",
    "\n",
    "    fine_tuner = CreateFineTuningData(api_key)\n",
    "    content = fine_tuner.read_document(file_path)\n",
    "    title = \"GPT-4 Vision Capabilities\"  # タイトルを設定\n",
    "    fine_tuner.create_fine_tuning_data(content, title)\n",
    "    fine_tuner.save_to_jsonl(output_filename)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to fine_tuning_data.jsonl\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# count number of token\n",
    "\n"
   ],
   "id": "47b5659a5838dfb0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## {prompt:XXX, completion: YYY}",
   "id": "d8763efa7bc08786"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 文字列に含まれる toke 数\n",
    "# model: text-embedding-3-small\n",
    "import tiktoken\n",
    "import pprint\n",
    "\n",
    "with open('fine_tuning_data.jsonl', 'r') as fp:\n",
    "    data_l = fp.read()\n",
    "\n",
    "def num_tokens_from_string(data_l: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(data_l))\n",
    "    return num_tokens\n",
    "\n",
    "num_tokens_from_string(\"tiktoken is great!\", \"cl100k_base\")\n"
   ],
   "id": "1f99c01c689a10e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Obtaining the embeddings: 埋め込みを取得する。\n",
    "from openai import OpenAI\n",
    "\n",
    "model_embedding = \"text-embedding-3-small\"\n",
    "with open('fine_tuning_data.jsonl', 'r') as fp:\n",
    "    data_jsonl = fp.read()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.embeddings.create(\n",
    "    input=data_jsonl,  # \"Your text string goes here\",\n",
    "    model=model_embedding\n",
    ")\n",
    "\n",
    "print(response.data[0].embedding)"
   ],
   "id": "635cd98618b903d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### token count\n",
    "| **Encoding name** | **OpenAI models** |\n",
    "|-------------------|-------------------|\n",
    "| cl100k_base       | gpt-4, gpt-3.5-turbo, text-embedding-ada-002, text-embedding-3-small, text-embedding-3-large |\n",
    "| p50k_base         | Codex models, text-davinci-002, text-davinci-003 |\n",
    "| r50k_base (or gpt2) | GPT-3 models like davinci |\n"
   ],
   "id": "e2eb141952c840fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pprint\n",
    "\n",
    "model='text-embedding-3-small'\n",
    "import tiktoken\n",
    "enc = tiktoken.get_encoding(\"o200k_base\")\n",
    "assert enc.decode(enc.encode(\"hello world\")) == \"hello world\"\n",
    "\n",
    "# To get the tokeniser corresponding to a specific model in the OpenAI API:\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4o\")"
   ],
   "id": "bc1b96c4962f664b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T23:14:04.966562Z",
     "start_time": "2024-08-13T23:14:01.762795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.get_encoding(\"o200k_base\")\n",
    "assert enc.decode(enc.encode(\"hello world\")) == \"hello world\"\n",
    "\n",
    "# To get the tokeniser corresponding to a specific model in the OpenAI API:\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4o-mini\")"
   ],
   "id": "d7b83283e09002eb",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T23:14:12.916594Z",
     "start_time": "2024-08-13T23:14:12.911369Z"
    }
   },
   "cell_type": "code",
   "source": "enc",
   "id": "12c913cc0b28fda0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Encoding 'o200k_base'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7a03a7b6d3643e28"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
